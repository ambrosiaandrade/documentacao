# Apache kafka

* **[Apache Kafka](https://kafka.apache.org/quickstart)**
* https://www.confluent.io/learn/spring-boot-kafka/

<!-- TODO colocar imagens, explicar termos -->

## üìö Tabela de conte√∫dos

- [Depend√™ncia e configura√ß√£o](#dependencia-e-configura√ß√£o)
- [Produtor](#produtor)
- [Consumidor](#consumidor)
- [Tratamento de exce√ß√£o](#tratamento-de-exce√ß√£o)
- [Configura√ß√£o](#configura√ß√£o)

## Breve explica√ß√£o
O Apache Kafka √© uma plataforma de mensageria distribu√≠da que permite a comunica√ß√£o ass√≠ncrona entre sistemas por meio do envio e recebimento de mensagens. Ele atua como um intermedi√°rio entre quem produz (envia) e quem consome (processa) mensagens.

Uma analogia √∫til √© a dos correios:

* Uma pessoa escreve uma carta (produtor), envia pelos correios (Kafka Broker), e outra pessoa a recebe (consumidor).

* Os correios organizam essas cartas por assunto, como pa√≠ses (t√≥picos), e dentro de cada pa√≠s, por cidade (parti√ß√µes).


**Fluxo b√°sico**
produtor -> broker (servidor Kafka) -> consumidor

**Principais conceitos**

| Termo         | Explica√ß√£o                                                                 |
| ------------- | -------------------------------------------------------------------------- |
| **Broker**    | Servidor Kafka que armazena os dados e gerencia os t√≥picos e parti√ß√µes.    |
| **Cluster**   | Conjunto de brokers Kafka trabalhando juntos para garantir escalabilidade. |
| **Topic**     | Categoria ou nome l√≥gico para agrupar mensagens (ex: `paises`).            |
| **Partition** | Subdivis√£o de um t√≥pico para paralelizar o processamento.                  |
| **Offset**    | Posi√ß√£o √∫nica da mensagem dentro de uma parti√ß√£o, como um √≠ndice.          |
| **Producer**  | Componente que envia (publica) mensagens para um t√≥pico.                   |
| **Consumer**  | Componente que l√™ (consome) mensagens de um t√≥pico.                        |

**Exemplo ilustrativo**
Imagine o t√≥pico paises, com as seguintes parti√ß√µes:
* paises-0 ‚Üí mensagens sobre "Brasil"
* paises-1 ‚Üí mensagens sobre "Chile"
* paises-2 ‚Üí mensagens sobre "Argentina"

Cada mensagem tem um offset, como se fosse a posi√ß√£o na fila daquela parti√ß√£o. O consumidor usa o offset para saber at√© onde j√° leu.

![kafka](./img/kafka.png)

## Depend√™ncia e configura√ß√£o
Arquivo ``pom.xml``
```java
<dependency>
    <groupId>org.springframework.kafka</groupId>
    <artifactId>spring-kafka</artifactId>
</dependency>
```
Arquivo ``application.properties``
```sh
# Apache Kafka
spring.kafka.bootstrap-servers=host.docker.internal:9092
spring.kafka.admin.auto-create=true

## Consumer
spring.kafka.consumer.group-id=test-group
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer

## Producer
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
app.kafka.topic=test-topic
```

* **bootstrap-servers** especifica qual o kafka broker(s) a aplica√ß√£o vai se conectar
* **key-deserializer** converte a chave da mensagem recebida de byte[] para String
* **value-deserializer** converte a mensagem recebida de byte[] para String
* **group-id** define o grupo de consumidores, Kafka usa isso para rastrear o consumo
* **key-serializer** converte a chave da mensagem que ser√° enviada de String para byte[]
* **value-serializer** converte a mensagem que ser√° enviada de String para byte[]

## Produtor
```java
@Autowired
private KafkaTemplate<String, String> kafkaTemplate;

@Value("${app.kafka.topic}")
private String TOPIC;

public void sendMessage(String message) {
    kafkaTemplate.send(TOPIC, message)
            .thenAccept(result -> {
                var meta = result.getRecordMetadata();
                log.info("[Kafka] Message sent successfully: topic={}, partition={}, offset={}, message={}",
                        meta.topic(), meta.partition(), meta.offset(), message);
            })
            .exceptionally(ex -> {
                log.error("[Kafka] Failed to send message: {}", message, ex);
                return null;
            });
}
```
### Com reenvio
* **Configura√ß√£o autom√°tica de reenvio**
* Kafka tentar√° reenviar a mensagem at√© 3 vezes se houver erro de rede ou erro transit√≥rio.
* N√£o cobre erros l√≥gicos, como exce√ß√µes em serializa√ß√£o.
* O produtor Kafka s√≥ faz retry autom√°tico em erros transit√≥rios (por exemplo: TimeoutException, NetworkException) n√£o cobre erros como falha de serializa√ß√£o, exce√ß√µes de neg√≥cio, nem InvalidTopicException
```sh
## Producer
# ...
spring.kafka.producer.retries= 3
spring.kafka.producer.retry-backoff-ms= 1000 # tempo de espera entre tentativas
```

* **Configura√ß√£o de um bean com Spring Retry**
* A alterna entre a pol√≠tica de reenvio via application.properties sem alterar c√≥digo
```java
@Configuration
public class KafkaRetryConfig {

    @Value("${spring.kafka.producer.retries}")
    private int retries;

    @Value("${spring.kafka.producer.retry-backoff-ms}")
    private int backoff;

    @Value("${app.kafka.retry-policy}")
    private String retryPolicyType;

    @Bean
    public RetryTemplate retryTemplate() {
        RetryTemplate template = new RetryTemplate();

        // Pol√≠tica de tentativas
        SimpleRetryPolicy retryPolicy = new SimpleRetryPolicy();
        retryPolicy.setMaxAttempts(retries);

        // Pol√≠tica de espera entre tentativas
        BackOffPolicy backOffPolicy = "exponential".equalsIgnoreCase(retryPolicyType) ?
                getExponentialBackOffPolicy() :
                getFixedBackOffPolicy();

        template.setRetryPolicy(retryPolicy);
        template.setBackOffPolicy(backOffPolicy);

        return template;
    }

    private FixedBackOffPolicy getFixedBackOffPolicy() {
        var backOffPolicy = new FixedBackOffPolicy();
        backOffPolicy.setBackOffPeriod(backoff);

        return backOffPolicy;
    }

    private ExponentialBackOffPolicy getExponentialBackOffPolicy() {
        var backOffPolicy = new ExponentialBackOffPolicy();
        backOffPolicy.setInitialInterval(1000);
        backOffPolicy.setMultiplier(2.0);
        backOffPolicy.setMaxInterval(5000);

        return backOffPolicy;
    }

}
```
* **No service pegando o RetryTemplate customizado**
```java
    @Autowired
    private RetryTemplate retryTemplate;

    private void sendMessageWithRetry(String message) {
        RetryCallback<Void, RuntimeException> callback = context ->{
            int attempt = context.getRetryCount() + 1;
            log.info("[Kafka] Tentativa {} de envio da mensagem: {}", attempt, message);

            try {
                SendResult<String, String> result = kafkaTemplate.send(TOPIC, message).get(); // .get() para propagar exce√ß√µes
                var meta = result.getRecordMetadata();
                log.info("[Kafka] Mensagem enviada com sucesso: topic={}, partition={}, offset={}",
                        meta.topic(), meta.partition(), meta.offset());
            } catch (Exception e) {
                log.warn("[Kafka] Erro ao tentar enviar mensagem na tentativa {}: {}", attempt, e.getMessage());
                throw new RuntimeException(e); // for√ßa o retry
            }

            return null;
        };

        RecoveryCallback<Void> recovery = context -> {
            // Callback final ap√≥s todas as tentativas falharem
            log.error("[Kafka] Todas as tentativas de envio falharam para a mensagem: {}", message);
            return null;
        };

        retryTemplate.execute(callback, recovery);
    }
```

## Consumidor
Com tratamento de erro
```java
@KafkaListener(
        topics = "${app.kafka.topic}",
        groupId = "${spring.kafka.consumer.group-id}",
        errorHandler = "kafkaErrorHandler")
public void consume(String message) {
    try {
        if (message.contains("error")) {
            throw new RuntimeException("Failed processing message");
        }
        processMessage(message);
        log.info("[Kafka_consume] Consumed: {}", message);
    } catch (Exception e) {
        log.error("[Kafka_consume] Failed to process message: {}", message, e);
    }
}
```

Com configura√ß√£o para tentar ler novamente
```java
@RetryableTopic(
        attempts = "3",
        backoff = @Backoff(delay = 2000),
        topicSuffixingStrategy = TopicSuffixingStrategy.SUFFIX_WITH_INDEX_VALUE
)
@KafkaListener(
        topics = "${app.kafka.topic}",
        groupId = "${spring.kafka.consumer.group-id}")
public void consumeWithRetry(String message) {
    try {
        if (message.contains("retry")) {
            throw new RuntimeException("Temporary failure");
        }
        processMessage(message);
        log.info("[Kafka_consumeWithRetry] Consumed: {}", message);
    } catch (Exception e) {
        log.error("[Kafka_consumeWithRetry] Failed to process message: {}", message, e);
    }
}
```

Busca mensagens do t√≥pico
_OBS: apenas para fins administrativos ou testes, em produ√ß√£o √© ``@KafkaListener``_
```java

@Autowired
private ConsumerFactory<String, String> consumerFactory;

public List<String> fetchMessagesFromKafka(int maxMessages) {
    List<String> messages = new ArrayList<>();

    try (KafkaConsumer<String, String> consumer = (KafkaConsumer<String, String>) consumerFactory.createConsumer()) {
        consumer.subscribe(List.of(topic));
        consumer.poll(Duration.ZERO); // for√ßa a atribui√ß√£o de parti√ß√µes

        int count = 0;

        while (count < maxMessages) {
            var records = consumer.poll(Duration.ofSeconds(2));

            for (var record : records) {
                messages.add(record.value());
                if (++count >= maxMessages) break;
            }

            consumer.commitSync();

            if (records.isEmpty()) break; // se n√£o veio nada, encerra
        }

    } catch (Exception e) {
        log.error("[Kafka] Erro ao buscar mensagens", e);
    }

    return messages;
}
```

## Tratamento de exce√ß√£o
**O mais simples**
```java
public class KafkaErrorHandler {

    @Bean
    public ConsumerAwareListenerErrorHandler kafkaErrorHandler() {
        return (message, exception, consumer) -> {
            log.error("[Kafka Error] Failed to process message: {}", message.getPayload(), exception);
            return null; // You can log, send to DLQ, or handle accordingly
        };
    }
}
```
**Um pouco mais avan√ßado com o envio para uma fila DLQ (Dead Letter Queue)**
```java
public class KafkaErrorHandler {

    @Autowired
    private KafkaTemplate<String, String> kafkaTemplate;

    @Bean
    public ConsumerAwareListenerErrorHandler kafkaErrorHandlerWithDLQ() {
        return (message, exception, consumer) -> {
            String payload = (String) message.getPayload();
            log.error("[Kafka Error] Failed to process message: {}", payload, exception);

            kafkaTemplate.send("my-dlq-topic", payload);
            return null;
        };
    }

}
```

**Mais avan√ßado e recomendado**
* O Spring Kafka tenta reprocessar (retries internos do listener).
* Se todas as tentativas falharem, ele envia a mensagem automaticamente para um t√≥pico DLQ.
```java
@Configuration
public class KafkaDLQConfig {

    @Autowired
    private KafkaTemplate<Object, Object> kafkaTemplate;

    @Bean
    public DeadLetterPublishingRecoverer recoverer() {
        return new DeadLetterPublishingRecoverer(kafkaTemplate,
                (record, ex) -> new TopicPartition(record.topic() + ".DLQ", record.partition()));
    }

    @Bean
    public DefaultErrorHandler errorHandler(DeadLetterPublishingRecoverer recoverer) {
        // M√°ximo de 3 tentativas + backoff exponencial
        ExponentialBackOff backOff = new ExponentialBackOff(1000L, 2.0);
        backOff.setMaxInterval(5000L);
    
        DefaultErrorHandler errorHandler = new DefaultErrorHandler(recoverer, backOff);
    
        // Voc√™ pode ignorar ou tratar exce√ß√µes espec√≠ficas tamb√©m:
        // errorHandler.addNotRetryableExceptions(IllegalArgumentException.class);
    
        return errorHandler;
    }

}
```
* Vincule o ErrorHandler ao KafkaListenerContainerFactory
```java
@Configuration
public class KafkaListenerConfig {

    @Value("${spring.kafka.bootstrap-servers}")
    private String bootstrapServers;

    @Value("${spring.kafka.consumer.group-id}")
    private String groupId;

    @Bean
    public ConsumerFactory<String, String> consumerFactory() {
        Map<String, Object> props = new HashMap<>();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);
        props.put(ConsumerConfig.GROUP_ID_CONFIG, groupId);
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");
        return new DefaultKafkaConsumerFactory<>(props);
    }

    @Bean
    public ConcurrentKafkaListenerContainerFactory<String, String> kafkaListenerContainerFactory(
            ConsumerFactory<String, String> consumerFactory,
            DefaultErrorHandler errorHandler
    ) {
        ConcurrentKafkaListenerContainerFactory<String, String> factory =
                new ConcurrentKafkaListenerContainerFactory<>();

        factory.setConsumerFactory(consumerFactory);
        factory.setCommonErrorHandler(errorHandler);

        return factory;
    }
}

```

* Listener normal (sem precisar declarar errorHandler = ...)
```java
@KafkaListener(topics = "my-topic")
public void consume(String message) {
    // Simula erro
    if (message.contains("fail")) {
        throw new RuntimeException("Erro no processamento!");
    }

    log.info("Mensagem processada: {}", message);
}

// Optional
@KafkaListener(topics = "my-topic.DLQ")
public void listenDLQ(String message) {
    log.warn("Mensagem recebida na DLQ: {}", message);
}
```

| Vantagem                                 | Descri√ß√£o                                |
| ---------------------------------------- | ---------------------------------------- |
| üîÅ Retenta automaticamente               | Com backoff                              |
| üßØ Redireciona falhas cr√≠ticas           | Evita perda de dados                     |
| üîç Ajuda na auditoria/debug              | O consumidor DLQ pode logar ou notificar |
| üß© Totalmente integrado com Spring Kafka | Sem c√≥digo extra no seu servi√ßo          |

------

## ‚úÖ Reorganiza√ß√£o:

1. **Separar as responsabilidades em tr√™s partes claras**:

   * üì¶ **KafkaProducerConfig** ‚Üí produ√ß√£o e retries manuais (se houver)
   * üì• **KafkaConsumerConfig** ‚Üí listeners + error handling (DefaultErrorHandler + DLQ)
   * ‚öôÔ∏è **KafkaProperties** ‚Üí centraliza tudo que vem do `application.yml`

2. **Reduzir o n√∫mero de classes sem perder clareza**

3. **Manter extens√≠vel e f√°cil de dar manuten√ß√£o**

---

## üìÅ Organiza√ß√£o final sugerida

### 1. ‚úÖ `KafkaProperties.java`
Mais informa√ß√µes em [configuration-properties](./configuration-properties.md)

```java
@Component
@ConfigurationProperties(prefix = "app.kafka")
public class KafkaProperties {

    private String topic;
    private int retries;
    private int retryBackoffMs;
    private String retryPolicy;

    // Getters e setters
}
```

No `application.yml`:

```yaml
app:
  kafka:
    topic: my-topic
    retries: 3
    retry-backoff-ms: 1000
    retry-policy: exponential
```

---

### 2. ‚úÖ `KafkaProducerConfig.java`

```java
@Configuration
public class KafkaProducerConfig {

    private final KafkaProperties props;

    public KafkaProducerConfig(KafkaProperties props) {
        this.props = props;
    }

    @Bean
    public RetryTemplate retryTemplate() {
        RetryTemplate template = new RetryTemplate();

        SimpleRetryPolicy retryPolicy = new SimpleRetryPolicy();
        retryPolicy.setMaxAttempts(props.getRetries());

        BackOffPolicy backOffPolicy = "exponential".equalsIgnoreCase(props.getRetryPolicy()) ?
                getExponentialBackOffPolicy() : getFixedBackOffPolicy();

        template.setRetryPolicy(retryPolicy);
        template.setBackOffPolicy(backOffPolicy);

        return template;
    }

    private FixedBackOffPolicy getFixedBackOffPolicy() {
        FixedBackOffPolicy policy = new FixedBackOffPolicy();
        policy.setBackOffPeriod(props.getRetryBackoffMs());
        return policy;
    }

    private ExponentialBackOffPolicy getExponentialBackOffPolicy() {
        ExponentialBackOffPolicy policy = new ExponentialBackOffPolicy();
        policy.setInitialInterval(1000);
        policy.setMultiplier(2.0);
        policy.setMaxInterval(5000);
        return policy;
    }
}
```

---

### 3. ‚úÖ `KafkaConsumerConfig.java`

```java
@Configuration
public class KafkaConsumerConfig {

    private final KafkaTemplate<Object, Object> kafkaTemplate;

    public KafkaConsumerConfig(KafkaTemplate<Object, Object> kafkaTemplate) {
        this.kafkaTemplate = kafkaTemplate;
    }

    @Bean
    public DeadLetterPublishingRecoverer deadLetterPublishingRecoverer() {
        return new DeadLetterPublishingRecoverer(kafkaTemplate,
                (record, ex) -> new TopicPartition(record.topic() + ".DLQ", record.partition()));
    }

    @Bean
    public DefaultErrorHandler errorHandler(DeadLetterPublishingRecoverer recoverer) {
        ExponentialBackOff backOff = new ExponentialBackOff(1000L, 2.0);
        backOff.setMaxInterval(5000L);

        return new DefaultErrorHandler(recoverer, backOff);
    }

    @Bean
    public ConsumerFactory<String, String> consumerFactory() {
        Map<String, Object> props = new HashMap<>();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);
        props.put(ConsumerConfig.GROUP_ID_CONFIG, groupId);
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");
        return new DefaultKafkaConsumerFactory<>(props);
    }

    @Bean
    public ConcurrentKafkaListenerContainerFactory<String, String> kafkaListenerContainerFactory(
            ConsumerFactory<String, String> consumerFactory,
            DefaultErrorHandler errorHandler) {

        ConcurrentKafkaListenerContainerFactory<String, String> factory =
                new ConcurrentKafkaListenerContainerFactory<>();

        factory.setConsumerFactory(consumerFactory);
        factory.setCommonErrorHandler(errorHandler);

        return factory;
    }
}
```

---

### 4. ‚úÖ `KafkaProducerService.java` (servi√ßo com retry opcional)

```java
@Service
public class KafkaProducerService {

    private final KafkaTemplate<String, String> kafkaTemplate;
    private final RetryTemplate retryTemplate;
    private final KafkaProperties props;

    public KafkaProducerService(KafkaTemplate<String, String> kafkaTemplate,
                                RetryTemplate retryTemplate,
                                KafkaProperties props) {
        this.kafkaTemplate = kafkaTemplate;
        this.retryTemplate = retryTemplate;
        this.props = props;
    }

    public void send(String message) {
        kafkaTemplate.send(props.getTopic(), message)
            .thenAccept(result -> log.info("[Kafka] Enviado com sucesso: {}", message))
            .exceptionally(ex -> {
                log.error("[Kafka] Falha ao enviar: {}", message, ex);
                return null;
            });
    }

    public void sendWithRetry(String message) {
        retryTemplate.execute(context -> {
            log.info("[Kafka] Tentando enviar (tentativa {}): {}", context.getRetryCount() + 1, message);
            kafkaTemplate.send(props.getTopic(), message).get();
            return null;
        }, context -> {
            log.error("[Kafka] Todas as tentativas falharam: {}", message);
            return null;
        });
    }
}
```

---

### 5. ‚úÖ Listener de consumo

```java
@KafkaListener(topics = "${app.kafka.topic}")
public void consume(String message) {
    log.info("Consumido: {}", message);

    if (message.contains("erro")) {
        throw new RuntimeException("Erro proposital");
    }
}
```

---

### 6. ‚úÖ Listener da DLQ

```java
@KafkaListener(topics = "${app.kafka.topic}.DLQ")
public void consumeDlq(String message) {
    log.warn("Mensagem foi para a DLQ: {}", message);
}
```

---

## ‚úÖ Resultado

üì¶ Organiza√ß√£o final:

```
src/main/java/
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ KafkaProducerConfig.java
‚îÇ   ‚îú‚îÄ‚îÄ KafkaConsumerConfig.java
‚îÇ   ‚îî‚îÄ‚îÄ KafkaProperties.java
‚îú‚îÄ‚îÄ service/
‚îÇ   ‚îî‚îÄ‚îÄ KafkaProducerService.java
‚îî‚îÄ‚îÄ listener/
    ‚îú‚îÄ‚îÄ MyKafkaListener.java
    ‚îî‚îÄ‚îÄ DlqKafkaListener.java
```

---

## ‚úÖ Conclus√£o

Voc√™ fica com:

* Configura√ß√µes separadas por responsabilidade (produtor, consumidor, propriedades)
* Zero duplica√ß√£o
* DLQ e retry funcionais
* Manuten√ß√£o e leitura muito mais simples

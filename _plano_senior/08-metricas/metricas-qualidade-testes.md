# üìä M√©tricas de Qualidade de Testes

## √çndice

1. [Vis√£o Geral](#1-vis√£o-geral)
2. [Mutation Score](#2-mutation-score)
3. [Diff Coverage](#3-diff-coverage)
4. [Flaky Rate](#4-flaky-rate)
5. [Lead Time de Testes](#5-lead-time-de-testes)
6. [Cobertura de C√≥digo](#6-cobertura-de-c√≥digo)
7. [M√©tricas de Resili√™ncia](#7-m√©tricas-de-resili√™ncia)
8. [M√©tricas de Performance](#8-m√©tricas-de-performance)
9. [M√©tricas de Neg√≥cio](#9-m√©tricas-de-neg√≥cio)
10. [Dashboard e Visualiza√ß√£o](#10-dashboard-e-visualiza√ß√£o)

---

## 1. Vis√£o Geral

### üéØ Por que M√©tricas?

M√©tricas objetivas transformam qualidade de testes de conceito subjetivo em pr√°tica mensur√°vel. Permitem:

- **Decis√µes baseadas em dados**: Quality gates automatizados
- **Visibilidade**: Progresso e regress√µes ficam √≥bvios
- **Melhoria cont√≠nua**: Identifica√ß√£o de padr√µes e tend√™ncias
- **Accountability**: Responsabilidade clara sobre qualidade

### üìà Princ√≠pios

1. **Mensur√°vel**: Deve poder ser coletada automaticamente
2. **Acion√°vel**: Deve orientar a√ß√µes concretas
3. **Relevante**: Deve correlacionar com qualidade real
4. **Simples**: Deve ser compreens√≠vel por todos

### ‚ö†Ô∏è Anti-patterns

- ‚ùå Usar apenas cobertura de linhas como m√©trica √∫nica
- ‚ùå N√£o estabelecer baselines e metas
- ‚ùå M√©tricas como fim (gaming the metrics)
- ‚ùå Ignorar contexto e trade-offs

---

## 2. Mutation Score

### üéØ Conceito

**Mutation Score** mede a efic√°cia dos testes em detectar bugs atrav√©s da introdu√ß√£o deliberada de muta√ß√µes (bugs sint√©ticos) no c√≥digo.

**F√≥rmula:**

```
Mutation Score = (Mutantes Mortos / Mutantes Totais) √ó 100
```

- **Mutante Morto**: Muta√ß√£o que faz pelo menos 1 teste falhar (‚úÖ bom)
- **Mutante Sobrevivente**: Muta√ß√£o que passa em todos os testes (‚ùå gap)

### üß™ Exemplo Pr√°tico

**C√≥digo Original:**

```java
public class DiscountCalculator {
    public double calculateDiscount(double price, int quantity) {
        if (quantity >= 10) {
            return price * 0.9; // 10% desconto
        }
        return price;
    }
}
```

**Muta√ß√µes Poss√≠veis:**

```java
// Muta√ß√£o 1: Operador relacional (>= ‚Üí >)
if (quantity > 10) { ... }

// Muta√ß√£o 2: Constante (10 ‚Üí 11)
if (quantity >= 11) { ... }

// Muta√ß√£o 3: Operador aritm√©tico (* ‚Üí /)
return price / 0.9;

// Muta√ß√£o 4: Constante (0.9 ‚Üí 0.8)
return price * 0.8;

// Muta√ß√£o 5: Remo√ß√£o de condi√ß√£o
return price * 0.9; // sempre aplica desconto
```

**Teste B√°sico (Mata 3 de 5):**

```java
@Test
void deveAplicarDescontoPara10Itens() {
    var calc = new DiscountCalculator();
    assertEquals(90.0, calc.calculateDiscount(100.0, 10));
}
// Mata: Muta√ß√£o 2, 3, 5
// Sobrevive: Muta√ß√£o 1 (quantity > 10), Muta√ß√£o 4 (0.9 vs 0.8)
// Mutation Score: 60%
```

**Teste Completo (Mata 5 de 5):**

```java
@ParameterizedTest
@CsvSource({
    "100.0, 9, 100.0",   // boundary inferior
    "100.0, 10, 90.0",   // boundary exato (mata Muta√ß√£o 1)
    "100.0, 11, 90.0",   // acima do limite
    "50.0, 10, 45.0"     // valor diferente (mata Muta√ß√£o 4)
})
void deveCalcularDescontoCorretamente(double price, int qty, double expected) {
    assertEquals(expected, new DiscountCalculator().calculateDiscount(price, qty));
}
// Mutation Score: 100%
```

### üîß Ferramentas

#### PITest (Java)

**pom.xml:**

```xml
<plugin>
    <groupId>org.pitest</groupId>
    <artifactId>pitest-maven</artifactId>
    <version>1.15.3</version>
    <dependencies>
        <dependency>
            <groupId>org.pitest</groupId>
            <artifactId>pitest-junit5-plugin</artifactId>
            <version>1.2.1</version>
        </dependency>
    </dependencies>
    <configuration>
        <targetClasses>
            <param>com.example.core.*</param>
        </targetClasses>
        <targetTests>
            <param>com.example.core.*</param>
        </targetTests>
        <mutators>
            <mutator>DEFAULTS</mutator>
        </mutators>
        <outputFormats>
            <outputFormat>HTML</outputFormat>
            <outputFormat>XML</outputFormat>
        </outputFormats>
        <timestampedReports>false</timestampedReports>
    </configuration>
</plugin>
```

**Execu√ß√£o:**

```bash
mvn org.pitest:pitest-maven:mutationCoverage
# Relat√≥rio em: target/pit-reports/index.html
```

#### Stryker (JavaScript/TypeScript)

**stryker.conf.json:**

```json
{
  "packageManager": "npm",
  "reporters": ["html", "clear-text", "progress", "dashboard"],
  "testRunner": "jest",
  "coverageAnalysis": "perTest",
  "mutate": ["src/**/*.ts", "!src/**/*.spec.ts"],
  "thresholds": {
    "high": 80,
    "low": 60,
    "break": 50
  }
}
```

**Execu√ß√£o:**

```bash
npx stryker run
# Relat√≥rio em: reports/mutation/html/index.html
```

### üìä Metas e Limiares

| Contexto                      | Meta  | Limiar Cr√≠tico | A√ß√£o                         |
| ----------------------------- | ----- | -------------- | ---------------------------- |
| **C√≥digo de neg√≥cio cr√≠tico** | ‚â• 90% | < 80%          | ‚ùå Bloquear merge            |
| **C√≥digo de neg√≥cio padr√£o**  | ‚â• 75% | < 60%          | ‚ö†Ô∏è Review obrigat√≥rio        |
| **Utilit√°rios**               | ‚â• 60% | < 40%          | üìù Documentar d√≠vida         |
| **C√≥digo legado**             | ‚â• 40% | N/A            | üìà Melhorar incrementalmente |

### üéØ Estrat√©gias de Melhoria

#### 1. Priorizar Mutantes Sobreviventes

**Script de an√°lise:**

```bash
# Extrair mutantes sobreviventes cr√≠ticos
grep "SURVIVED" target/pit-reports/mutations.xml \
  | grep -E "(CONDITIONAL|MATH|RETURN)" \
  | sort | uniq -c | sort -rn
```

#### 2. Foco em Boundaries

```java
// ‚ùå Teste fraco
@Test
void testeGenerico() {
    assertTrue(validator.isValid(5));
}

// ‚úÖ Teste forte (mata muta√ß√µes de boundary)
@ParameterizedTest
@ValueSource(ints = {0, 1, 9, 10, 11, 99, 100, 101})
void deveValidarBoundaries(int value) {
    boolean expected = value >= 1 && value <= 100;
    assertEquals(expected, validator.isValid(value));
}
```

#### 3. Testar Nega√ß√µes

```java
// ‚ùå Testa apenas happy path
@Test
void deveRetornarUsuarioQuandoExistir() {
    when(repo.findById(1L)).thenReturn(Optional.of(user));
    assertNotNull(service.getUser(1L));
}

// ‚úÖ Testa ambos os caminhos
@Test
void deveRetornarUsuarioQuandoExistir() {
    when(repo.findById(1L)).thenReturn(Optional.of(user));
    assertEquals("John", service.getUser(1L).getName());
}

@Test
void deveLancarExcecaoQuandoNaoExistir() {
    when(repo.findById(999L)).thenReturn(Optional.empty());
    assertThrows(NotFoundException.class, () -> service.getUser(999L));
}
```

### üìà Coleta Cont√≠nua

**GitHub Actions:**

```yaml
name: Mutation Testing

on:
  pull_request:
    branches: [main]

jobs:
  pitest:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
        with:
          fetch-depth: 0 # hist√≥rico completo para diff

      - name: Set up JDK 17
        uses: actions/setup-java@v3
        with:
          java-version: 17

      - name: Run Mutation Tests
        run: mvn clean test org.pitest:pitest-maven:mutationCoverage

      - name: Extract Score
        id: score
        run: |
          SCORE=$(grep -oP 'mutationCoverage>\K[0-9]+' target/pit-reports/mutations.xml | head -1)
          echo "score=$SCORE" >> $GITHUB_OUTPUT

      - name: Check Threshold
        run: |
          if [ ${{ steps.score.outputs.score }} -lt 70 ]; then
            echo "‚ùå Mutation score (${{ steps.score.outputs.score }}%) abaixo do limiar (70%)"
            exit 1
          fi
          echo "‚úÖ Mutation score: ${{ steps.score.outputs.score }}%"

      - name: Upload Report
        uses: actions/upload-artifact@v3
        with:
          name: pitest-report
          path: target/pit-reports/
```

### ‚ö†Ô∏è Pitfalls

1. **Muta√ß√£o de c√≥digo n√£o cr√≠tico**: Foco em paths importantes
2. **Timeouts**: Ajustar timeout para testes lentos
3. **Equivalentes**: Alguns mutantes s√£o logicamente equivalentes (falso positivo)
4. **Custo**: Mutation testing √© lento (rodar incremental ou agendado)

---

## 3. Diff Coverage

### üéØ Conceito

**Diff Coverage** mede a cobertura de testes **apenas nas linhas modificadas** em um PR/commit. Mais relevante que cobertura total para quality gates.

**F√≥rmula:**

```
Diff Coverage = (Linhas Modificadas Cobertas / Linhas Modificadas Totais) √ó 100
```

### üß™ Exemplo

**Git Diff:**

```diff
 public class OrderService {
     public void createOrder(Order order) {
         validateOrder(order);
+        if (order.getTotal() > 1000) {
+            applyVipDiscount(order);
+        }
         repository.save(order);
     }
 }
```

**An√°lise:**

- **Linhas modificadas**: 3 (linhas com `+`)
- **Linhas cobertas por testes**: 2
- **Diff Coverage**: 66.7%

### üîß Ferramentas

#### Codecov

**codecov.yml:**

```yaml
coverage:
  status:
    project:
      default:
        target: auto # mant√©m cobertura total
        threshold: 0.5% # toler√¢ncia
    patch: # diff coverage
      default:
        target: 80% # linhas novas devem ter 80%+
        threshold: 5%
        if_ci_failed: error

comment:
  layout: "diff, files"
  behavior: default
```

**GitHub Actions:**

```yaml
- name: Upload Coverage to Codecov
  uses: codecov/codecov-action@v3
  with:
    token: ${{ secrets.CODECOV_TOKEN }}
    files: ./target/site/jacoco/jacoco.xml
    flags: unittests
    fail_ci_if_error: true
```

#### Diff-Cover (Python)

```bash
# Gerar coverage
pytest --cov=src --cov-report=xml

# Analisar diff
diff-cover coverage.xml --compare-branch=origin/main --fail-under=80

# Sa√≠da:
# Diff Coverage: 85.7%
# src/order_service.py (3 lines): 66.7%
#   Line 42: NOT COVERED
# ‚úÖ PASSED (threshold: 80%)
```

#### JaCoCo + Diffblue Cover (Java)

**Maven Plugin:**

```xml
<plugin>
    <groupId>org.jacoco</groupId>
    <artifactId>jacoco-maven-plugin</artifactId>
    <version>0.8.11</version>
    <executions>
        <execution>
            <id>default-prepare-agent</id>
            <goals>
                <goal>prepare-agent</goal>
            </goals>
        </execution>
        <execution>
            <id>report</id>
            <phase>test</phase>
            <goals>
                <goal>report</goal>
            </goals>
        </execution>
        <execution>
            <id>check</id>
            <goals>
                <goal>check</goal>
            </goals>
            <configuration>
                <rules>
                    <rule>
                        <element>BUNDLE</element>
                        <limits>
                            <limit>
                                <counter>LINE</counter>
                                <value>COVEREDRATIO</value>
                                <minimum>0.80</minimum>
                            </limit>
                        </limits>
                    </rule>
                </rules>
            </configuration>
        </execution>
    </executions>
</plugin>
```

**Script de Diff Coverage:**

```bash
#!/bin/bash
# scripts/diff-coverage.sh

BASE_BRANCH=${1:-origin/main}
THRESHOLD=${2:-80}

# Gerar coverage report
mvn clean test jacoco:report

# Obter linhas modificadas
git diff $BASE_BRANCH --unified=0 -- '*.java' \
  | grep -E '^\+' | grep -v '^\+\+\+' \
  | awk '{print $1}' > /tmp/changed-lines.txt

# Analisar coverage das linhas modificadas
python3 scripts/analyze-diff-coverage.py \
  --coverage target/site/jacoco/jacoco.xml \
  --changed /tmp/changed-lines.txt \
  --threshold $THRESHOLD
```

**analyze-diff-coverage.py:**

```python
import xml.etree.ElementTree as ET
import sys
import argparse

def analyze_diff_coverage(coverage_file, changed_lines_file, threshold):
    tree = ET.parse(coverage_file)
    root = tree.getroot()

    total_changed = 0
    covered_changed = 0

    with open(changed_lines_file, 'r') as f:
        changed_files = {}
        for line in f:
            # Parse: src/main/java/com/example/Order.java:42
            parts = line.strip().split(':')
            if len(parts) == 2:
                file_path, line_num = parts
                if file_path not in changed_files:
                    changed_files[file_path] = []
                changed_files[file_path].append(int(line_num))

    for package in root.findall('.//package'):
        for sourcefile in package.findall('.//sourcefile'):
            file_name = sourcefile.get('name')

            for file_path, lines in changed_files.items():
                if file_name in file_path:
                    for line_elem in sourcefile.findall('.//line'):
                        line_num = int(line_elem.get('nr'))
                        if line_num in lines:
                            total_changed += 1
                            ci = int(line_elem.get('ci', 0))
                            if ci > 0:
                                covered_changed += 1

    if total_changed == 0:
        print("‚úÖ Nenhuma linha execut√°vel modificada")
        return 0

    diff_coverage = (covered_changed / total_changed) * 100

    print(f"üìä Diff Coverage Report")
    print(f"   Linhas modificadas: {total_changed}")
    print(f"   Linhas cobertas: {covered_changed}")
    print(f"   Diff Coverage: {diff_coverage:.1f}%")
    print(f"   Threshold: {threshold}%")

    if diff_coverage < threshold:
        print(f"‚ùå FAILED: Diff coverage abaixo do limiar")
        return 1

    print(f"‚úÖ PASSED")
    return 0

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--coverage', required=True)
    parser.add_argument('--changed', required=True)
    parser.add_argument('--threshold', type=float, default=80.0)

    args = parser.parse_args()
    sys.exit(analyze_diff_coverage(args.coverage, args.changed, args.threshold))
```

### üìä Metas e Limiares

| Tipo de Mudan√ßa          | Meta  | Limiar Cr√≠tico | Exce√ß√£o                         |
| ------------------------ | ----- | -------------- | ------------------------------- |
| **Novo c√≥digo**          | 100%  | < 80%          | C√≥digo experimental             |
| **Refatora√ß√£o**          | 100%  | < 90%          | Sem l√≥gica nova                 |
| **Bug fix**              | 100%  | < 100%         | Deve ter teste reproduzindo bug |
| **C√≥digo legado tocado** | ‚â• 50% | < 30%          | Melhorar incrementalmente       |

### üéØ Estrat√©gias

#### 1. Pre-commit Hook

```bash
#!/bin/bash
# .git/hooks/pre-commit

echo "üîç Verificando diff coverage..."

# Staged files
STAGED_FILES=$(git diff --cached --name-only --diff-filter=ACM | grep '\.java$')

if [ -z "$STAGED_FILES" ]; then
    echo "‚úÖ Nenhum arquivo Java modificado"
    exit 0
fi

# Rodar testes afetados
mvn test -Dtest="*Test"

# Analisar diff coverage
bash scripts/diff-coverage.sh HEAD 80

if [ $? -ne 0 ]; then
    echo "‚ùå Diff coverage insuficiente. Use 'git commit --no-verify' para for√ßar (n√£o recomendado)."
    exit 1
fi

echo "‚úÖ Diff coverage adequado"
exit 0
```

#### 2. Bot de PR

**GitHub Action:**

```yaml
- name: Comment PR with Diff Coverage
  uses: actions/github-script@v6
  with:
    script: |
      const fs = require('fs');
      const report = fs.readFileSync('diff-coverage-report.txt', 'utf8');

      github.rest.issues.createComment({
        issue_number: context.issue.number,
        owner: context.repo.owner,
        repo: context.repo.repo,
        body: `## üìä Diff Coverage Report\n\n\`\`\`\n${report}\n\`\`\``
      });
```

### ‚ö†Ô∏è Pitfalls

1. **C√≥digo n√£o execut√°vel**: Coment√°rios, imports (filtrar)
2. **Testes unit√°rios modificados**: N√£o contar como linhas modificadas
3. **C√≥digo gerado**: Excluir de an√°lise
4. **Merge commits**: Analisar apenas diff do PR, n√£o do merge

---

## 4. Flaky Rate

### üéØ Conceito

**Flaky Test** √© um teste n√£o-determin√≠stico que passa ou falha intermitentemente sem mudan√ßa no c√≥digo. √â uma das maiores fontes de frustra√ß√£o e eros√£o de confian√ßa.

**F√≥rmula:**

```
Flaky Rate = (Testes Flaky / Total de Testes) √ó 100
```

**Crit√©rio de Flaky:**

- Teste falha e passa alternadamente em m√∫ltiplas execu√ß√µes
- Sem mudan√ßa de c√≥digo entre execu√ß√µes
- Geralmente relacionado a timing, concorr√™ncia, estado compartilhado

### üß™ Causas Comuns

#### 1. Depend√™ncia de Tempo

```java
// ‚ùå Flaky: depende de tempo de processamento
@Test
void deveProcessarEmMenosDeUmSegundo() {
    long start = System.currentTimeMillis();
    service.processLargeData();
    long duration = System.currentTimeMillis() - start;
    assertTrue(duration < 1000); // pode falhar em CI com menos recursos
}

// ‚úÖ N√£o-flaky: usa timeout assertivo
@Test
@Timeout(value = 5, unit = TimeUnit.SECONDS)
void deveProcessarDentroDoTimeout() {
    service.processLargeData();
    // Se passar de 5s, JUnit falha automaticamente
}
```

#### 2. Async sem Sincroniza√ß√£o

```java
// ‚ùå Flaky: verifica antes do processamento ass√≠ncrono
@Test
void deveEnviarEmailAssincrono() {
    service.sendEmailAsync(user);
    Thread.sleep(100); // race condition
    verify(emailSender).send(any());
}

// ‚úÖ N√£o-flaky: usa Awaitility
@Test
void deveEnviarEmailAssincrono() {
    service.sendEmailAsync(user);

    await().atMost(Duration.ofSeconds(5))
           .untilAsserted(() -> verify(emailSender).send(any()));
}
```

#### 3. Estado Compartilhado

```java
// ‚ùå Flaky: testes compartilham estado
public class Flaky Test {
    private static List<String> cache = new ArrayList<>(); // compartilhado!

    @Test
    void teste1() {
        cache.add("A");
        assertEquals(1, cache.size());
    }

    @Test
    void teste2() {
        cache.add("B");
        assertEquals(1, cache.size()); // falha se teste1 rodar antes
    }
}

// ‚úÖ N√£o-flaky: isolamento completo
public class NonFlakyTest {
    private List<String> cache; // inst√¢ncia por teste

    @BeforeEach
    void setUp() {
        cache = new ArrayList<>();
    }

    @Test
    void teste1() {
        cache.add("A");
        assertEquals(1, cache.size());
    }

    @Test
    void teste2() {
        cache.add("B");
        assertEquals(1, cache.size());
    }
}
```

#### 4. Ordem de Execu√ß√£o

```java
// ‚ùå Flaky: depende de ordem de inser√ß√£o em banco
@Test
void deveBuscarPrimeiroUsuario() {
    User first = userRepository.findAll().get(0);
    assertEquals("John", first.getName()); // depende de ordem
}

// ‚úÖ N√£o-flaky: busca espec√≠fica
@Test
void deveBuscarUsuarioPorId() {
    User user = userRepository.findById(1L).orElseThrow();
    assertEquals("John", user.getName());
}
```

#### 5. Gera√ß√£o Aleat√≥ria

```java
// ‚ùå Flaky: usa UUID real
@Test
void deveGerarIdUnico() {
    String id = service.generateId(); // UUID.randomUUID()
    assertTrue(id.startsWith("usr-")); // pode passar ou falhar aleatoriamente
}

// ‚úÖ N√£o-flaky: mocka gera√ß√£o
@Test
void deveGerarIdUnico() {
    when(uuidGenerator.generate()).thenReturn(UUID.fromString("123e4567-e89b-12d3-a456-426614174000"));
    String id = service.generateId();
    assertEquals("usr-123e4567-e89b-12d3-a456-426614174000", id);
}
```

### üîß Ferramentas de Detec√ß√£o

#### 1. Maven Surefire (Rerun)

```xml
<plugin>
    <groupId>org.apache.maven.plugins</groupId>
    <artifactId>maven-surefire-plugin</artifactId>
    <version>3.2.2</version>
    <configuration>
        <rerunFailingTestsCount>3</rerunFailingTestsCount>
        <reportsDirectory>${project.build.directory}/surefire-reports-rerun</reportsDirectory>
    </configuration>
</plugin>
```

**An√°lise:**

```bash
# Testes que passaram ap√≥s rerun = flaky
grep -l "Flakes:" target/surefire-reports-rerun/*.xml
```

#### 2. Gradle Test Retry Plugin

```groovy
plugins {
    id 'org.gradle.test-retry' version '1.5.7'
}

test {
    retry {
        maxRetries = 3
        maxFailures = 5
        failOnPassedAfterRetry = true // marcar como falha mesmo se passar
    }
}
```

#### 3. Script de Detec√ß√£o Manual

```bash
#!/bin/bash
# scripts/detect-flaky.sh

TEST_CLASS=${1:-"**/*Test.java"}
RUNS=${2:-10}

echo "üîç Executando testes $RUNS vezes para detectar flakiness..."

for i in $(seq 1 $RUNS); do
    echo "Run $i/$RUNS..."
    mvn test -Dtest="$TEST_CLASS" > /tmp/test-run-$i.log 2>&1

    if [ $? -ne 0 ]; then
        echo "  ‚ùå Falhou"
        echo "$i" >> /tmp/failed-runs.txt
    else
        echo "  ‚úÖ Passou"
        echo "$i" >> /tmp/passed-runs.txt
    fi
done

FAILURES=$(wc -l < /tmp/failed-runs.txt 2>/dev/null || echo 0)
PASSES=$(wc -l < /tmp/passed-runs.txt 2>/dev/null || echo 0)

echo ""
echo "üìä Resultado:"
echo "   Passou: $PASSES/$RUNS"
echo "   Falhou: $FAILURES/$RUNS"

if [ $FAILURES -gt 0 ] && [ $PASSES -gt 0 ]; then
    echo "   ‚ö†Ô∏è  FLAKY DETECTADO!"
    exit 1
elif [ $FAILURES -eq $RUNS ]; then
    echo "   ‚ùå Teste consistentemente falhando (n√£o flaky, bug real)"
    exit 2
else
    echo "   ‚úÖ Teste est√°vel"
    exit 0
fi
```

#### 4. Jenkins Flaky Test Plugin

```groovy
// Jenkinsfile
pipeline {
    agent any
    stages {
        stage('Test') {
            steps {
                sh 'mvn test'
            }
            post {
                always {
                    junit testResults: '**/target/surefire-reports/*.xml',
                          allowEmptyResults: true

                    // Plugin detecta flaky automaticamente
                    step([$class: 'FlakeyTestResultsPublisher'])
                }
            }
        }
    }
}
```

### üìä Metas e Limiares

| Contexto           | Meta   | Limiar Cr√≠tico | A√ß√£o                   |
| ------------------ | ------ | -------------- | ---------------------- |
| **Suite completa** | 0%     | > 1%           | üö® Alerta urgente      |
| **Por m√≥dulo**     | 0%     | > 2%           | ‚ö†Ô∏è Investigar          |
| **Novos testes**   | 0%     | > 0%           | ‚ùå Bloquear merge      |
| **Testes E2E**     | < 0.5% | > 3%           | üìù Documentar e isolar |

### üéØ Estrat√©gias de Mitiga√ß√£o

#### 1. Isolamento de Testes

```java
// Usar @DirtiesContext para Spring
@SpringBootTest
@DirtiesContext(classMode = ClassMode.AFTER_EACH_TEST_METHOD)
class IsolatedTest {
    // Cada teste recebe contexto limpo
}

// Usar TestContainers para bancos
@Testcontainers
class DatabaseTest {
    @Container
    private static PostgreSQLContainer<?> postgres =
        new PostgreSQLContainer<>("postgres:15-alpine");

    @BeforeEach
    void cleanDatabase() {
        // Limpar entre testes
        jdbcTemplate.execute("TRUNCATE TABLE users CASCADE");
    }
}
```

#### 2. Clock Mockado

```java
// Injetar Clock
public class OrderService {
    private final Clock clock;

    public OrderService(Clock clock) {
        this.clock = clock;
    }

    public Order createOrder() {
        Order order = new Order();
        order.setCreatedAt(Instant.now(clock));
        return order;
    }
}

// Teste determin√≠stico
@Test
void deveUsarTimestampFixo() {
    Clock fixedClock = Clock.fixed(
        Instant.parse("2025-01-15T10:00:00Z"),
        ZoneId.of("UTC")
    );

    OrderService service = new OrderService(fixedClock);
    Order order = service.createOrder();

    assertEquals(Instant.parse("2025-01-15T10:00:00Z"), order.getCreatedAt());
}
```

#### 3. Awaitility para Async

```java
@Test
void deveProcessarEventoAssincrono() {
    eventPublisher.publish(new OrderCreatedEvent(order));

    await().atMost(Duration.ofSeconds(5))
           .pollInterval(Duration.ofMillis(100))
           .untilAsserted(() -> {
               Order processed = orderRepository.findById(order.getId()).orElseThrow();
               assertEquals(OrderStatus.CONFIRMED, processed.getStatus());
           });
}
```

#### 4. Quarentena de Flaky Tests

```java
// JUnit 5: tag para isolar flaky tests
@Tag("flaky")
@Disabled("Flaky: issue #1234")
@Test
void testeComProblemaConhecido() {
    // Desabilitado at√© fix
}
```

**Maven profile para rodar s√≥ flaky:**

```xml
<profile>
    <id>flaky-tests</id>
    <build>
        <plugins>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-surefire-plugin</artifactId>
                <configuration>
                    <groups>flaky</groups>
                </configuration>
            </plugin>
        </plugins>
    </build>
</profile>
```

```bash
# Rodar apenas flaky tests
mvn test -Pflaky-tests
```

### üìà Coleta Cont√≠nua

**Script de coleta semanal:**

```bash
#!/bin/bash
# scripts/weekly-flaky-report.sh

DAYS=7
RUNS_PER_TEST=5

echo "üìä Relat√≥rio de Flaky Tests (√∫ltimos $DAYS dias)"
echo "============================================="

# Obter testes modificados recentemente
RECENT_TESTS=$(git log --since="$DAYS days ago" --name-only --pretty=format: \
  | grep Test.java | sort | uniq)

for test in $RECENT_TESTS; do
    echo ""
    echo "üß™ Testando: $test"

    bash scripts/detect-flaky.sh "$test" $RUNS_PER_TEST

    if [ $? -eq 1 ]; then
        echo "   ‚ö†Ô∏è  FLAKY - Criar issue"
        # Criar issue automaticamente
        gh issue create \
          --title "Flaky Test: $test" \
          --body "Detectado em $(date). Rodar scripts/detect-flaky.sh $test 10 para reproduzir." \
          --label "flaky-test,priority-high"
    fi
done
```

### ‚ö†Ô∏è Pitfalls

1. **Esconder flaky com reruns**: Apenas mascara o problema
2. **Ignorar flaky em E2E**: "√â esperado" - eros√£o de confian√ßa
3. **N√£o registrar hist√≥rico**: Perder padr√µes de quando ocorre
4. **Executar testes em paralelo sem isolamento**: Aumenta flakiness

---

## 5. Lead Time de Testes

### üéØ Conceito

**Lead Time de Testes** mede o tempo desde o commit at√© o feedback de qualidade (testes passando/falhando).

**F√≥rmula:**

```
Lead Time = Tempo de Feedback - Tempo de Commit
```

**Categorias:**

- **Unit Tests**: < 1 min
- **Integration Tests**: 1-5 min
- **E2E Tests**: 5-15 min
- **Performance Tests**: 15-30 min

### üìä Metas

| Tipo             | Meta     | Limiar Cr√≠tico | Impacto                   |
| ---------------- | -------- | -------------- | ------------------------- |
| **Unit (local)** | < 30s    | > 2 min        | Desenvolvedores n√£o rodam |
| **Unit (CI)**    | < 2 min  | > 5 min        | Feedback lento            |
| **Integration**  | < 5 min  | > 10 min       | Merge demorado            |
| **E2E**          | < 15 min | > 30 min       | Deploy bloqueado          |

### üîß Otimiza√ß√µes

#### 1. Paraleliza√ß√£o

```xml
<!-- Maven Surefire: rodar em paralelo -->
<plugin>
    <groupId>org.apache.maven.plugins</groupId>
    <artifactId>maven-surefire-plugin</artifactId>
    <configuration>
        <parallel>methods</parallel>
        <threadCount>4</threadCount>
        <perCoreThreadCount>true</perCoreThreadCount>
    </configuration>
</plugin>
```

```groovy
// Gradle: paralelo por padr√£o
test {
    maxParallelForks = Runtime.runtime.availableProcessors().intdiv(2) ?: 1
}
```

#### 2. Test Sharding (CI)

```yaml
# GitHub Actions: dividir testes em m√∫ltiplos jobs
jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        shard: [1, 2, 3, 4]
    steps:
      - name: Run Tests (Shard ${{ matrix.shard }}/4)
        run: |
          mvn test -Dshard=${{ matrix.shard }} -DshardTotal=4
```

**Maven plugin para sharding:**

```xml
<plugin>
    <groupId>org.apache.maven.plugins</groupId>
    <artifactId>maven-surefire-plugin</artifactId>
    <configuration>
        <groups>shard-${shard}</groups>
    </configuration>
</plugin>
```

#### 3. Smart Test Selection

**Apenas testes afetados por mudan√ßas:**

```bash
#!/bin/bash
# scripts/smart-test-selection.sh

CHANGED_FILES=$(git diff --name-only origin/main...HEAD)

# Mapear arquivos mudados para testes
AFFECTED_TESTS=""

for file in $CHANGED_FILES; do
    # Exemplo simples: se Order.java mudou, rodar OrderTest.java
    if [[ $file == *"Order.java" ]]; then
        AFFECTED_TESTS="$AFFECTED_TESTS OrderTest"
    fi
done

if [ -z "$AFFECTED_TESTS" ]; then
    echo "‚úÖ Nenhum teste afetado"
    exit 0
fi

echo "üß™ Rodando testes afetados: $AFFECTED_TESTS"
mvn test -Dtest="$AFFECTED_TESTS"
```

**Bazel (an√°lise de depend√™ncias built-in):**

```bash
# Rodar apenas testes afetados por mudan√ßas
bazel test --test_tag_filters=-slow //src/...
```

#### 4. Cache de Dependencies

```yaml
# GitHub Actions: cache de Maven
- name: Cache Maven packages
  uses: actions/cache@v3
  with:
    path: ~/.m2/repository
    key: ${{ runner.os }}-maven-${{ hashFiles('**/pom.xml') }}
    restore-keys: |
      ${{ runner.os }}-maven-
```

### üìà M√©tricas de Acompanhamento

```python
# scripts/track-test-lead-time.py
import json
import requests
from datetime import datetime

def get_ci_duration(run_id):
    """Obter dura√ß√£o de CI run do GitHub Actions"""
    url = f"https://api.github.com/repos/owner/repo/actions/runs/{run_id}"
    headers = {"Authorization": f"token {GITHUB_TOKEN}"}

    response = requests.get(url, headers=headers)
    data = response.json()

    started = datetime.fromisoformat(data['run_started_at'].replace('Z', '+00:00'))
    completed = datetime.fromisoformat(data['updated_at'].replace('Z', '+00:00'))

    duration_seconds = (completed - started).total_seconds()

    return {
        'run_id': run_id,
        'duration_seconds': duration_seconds,
        'duration_minutes': duration_seconds / 60,
        'conclusion': data['conclusion']
    }

def calculate_p50_p95(durations):
    """Calcular percentis"""
    sorted_durations = sorted(durations)
    n = len(sorted_durations)

    p50_index = int(n * 0.5)
    p95_index = int(n * 0.95)

    return {
        'p50': sorted_durations[p50_index],
        'p95': sorted_durations[p95_index],
        'min': sorted_durations[0],
        'max': sorted_durations[-1],
        'mean': sum(sorted_durations) / n
    }

# Uso
durations = [get_ci_duration(run_id)['duration_minutes']
             for run_id in last_100_runs]

stats = calculate_p50_p95(durations)
print(f"üìä Lead Time Stats (√∫ltimos 100 runs):")
print(f"   P50: {stats['p50']:.1f} min")
print(f"   P95: {stats['p95']:.1f} min")
print(f"   M√©dia: {stats['mean']:.1f} min")
```

---

## 6. Cobertura de C√≥digo

### üéØ Conceito Expandido

Cobertura tradicional (linhas, branches) √© **necess√°ria mas n√£o suficiente**. Complementar com:

- **Path Coverage**: Todos os caminhos poss√≠veis
- **Condition Coverage**: Todas as condi√ß√µes booleanas (true/false)
- **Data Flow Coverage**: Uso de vari√°veis (defini√ß√£o ‚Üí uso)

### üìä Metas Contextuais

| Tipo de C√≥digo            | Meta Linhas | Meta Branches | Meta Muta√ß√£o |
| ------------------------- | ----------- | ------------- | ------------ |
| **Domain/Business Logic** | 95%         | 90%           | 85%          |
| **Controllers/API**       | 85%         | 80%           | 70%          |
| **Repositories/DAO**      | 80%         | 75%           | 65%          |
| **Configurations**        | 60%         | 50%           | N/A          |
| **DTOs/Entities**         | 40%         | N/A           | N/A          |

### ‚ö†Ô∏è Armadilhas

```java
// ‚ùå 100% cobertura mas teste in√∫til
@Test
void testeComCoberturaInutil() {
    calculator.divide(10, 2); // nenhum assert!
    // Cobertura: 100% | Valor: 0%
}

// ‚úÖ Cobertura + valida√ß√£o
@Test
void deveCalcularDivisao() {
    assertEquals(5.0, calculator.divide(10, 2));
}

@Test
void deveLancarExcecaoAoDividirPorZero() {
    assertThrows(ArithmeticException.class, () -> calculator.divide(10, 0));
}
```

---

## 7. M√©tricas de Resili√™ncia

### üéØ Conceito

Medir a qualidade de testes relacionados a **resili√™ncia** (falhas, lat√™ncia, indisponibilidade).

### üìä M√©tricas-Chave

#### 1. Resili√™ncia Test Coverage

```
Resili√™ncia Coverage = (Cen√°rios de Falha Testados / Cen√°rios Poss√≠veis) √ó 100
```

**Exemplo:**

```java
// Matriz de cen√°rios
// [‚úÖ] Timeout de rede
// [‚úÖ] Resposta 5xx
// [‚úÖ] Resposta 4xx
// [‚úÖ] Payload corrompido
// [‚ùå] Conex√£o recusada
// [‚ùå] Circuit breaker aberto
// Resili√™ncia Coverage: 66.7% (4/6)
```

#### 2. Chaos Test Pass Rate

```
Chaos Pass Rate = (Chaos Tests Passando / Total Chaos Tests) √ó 100
```

**Target**: 100% (sistema deve se recuperar de todas as falhas injetadas)

#### 3. MTTR (Mean Time To Recovery) em Testes

```java
@Test
void deveMedirTempoDeRecuperacao() {
    // Simular falha
    circuitBreaker.transitionToOpenState();

    long start = System.currentTimeMillis();

    // Aguardar recupera√ß√£o
    await().atMost(Duration.ofSeconds(10))
           .until(() -> circuitBreaker.getState() == State.CLOSED);

    long recoveryTime = System.currentTimeMillis() - start;

    // MTTR deve ser < 5s
    assertThat(recoveryTime).isLessThan(5000);
}
```

---

## 8. M√©tricas de Performance

### üìä M√©tricas-Chave

#### 1. Lat√™ncia (Percentis)

```java
@Test
void deveAtenderLatenciaP95() {
    List<Long> latencies = new ArrayList<>();

    for (int i = 0; i < 100; i++) {
        long start = System.nanoTime();
        service.process();
        long duration = System.nanoTime() - start;
        latencies.add(duration / 1_000_000); // ms
    }

    Collections.sort(latencies);
    long p95 = latencies.get(94); // posi√ß√£o 95 de 100

    assertThat(p95).isLessThan(100); // P95 < 100ms
}
```

#### 2. Throughput

```java
@Test
void deveSuportarThroughputMinimo() {
    int requests = 1000;
    long start = System.currentTimeMillis();

    IntStream.range(0, requests).parallel()
        .forEach(i -> service.process());

    long duration = System.currentTimeMillis() - start;
    double throughput = (requests * 1000.0) / duration; // req/s

    assertThat(throughput).isGreaterThan(100); // > 100 req/s
}
```

#### 3. Resource Usage

```java
@Test
void naoDeveVazarMemoria() {
    Runtime runtime = Runtime.getRuntime();
    long before = runtime.totalMemory() - runtime.freeMemory();

    // Executar opera√ß√£o 1000x
    for (int i = 0; i < 1000; i++) {
        service.processLargeData();
    }

    System.gc();
    Thread.sleep(100);

    long after = runtime.totalMemory() - runtime.freeMemory();
    long growth = after - before;

    // Crescimento de mem√≥ria < 10MB
    assertThat(growth).isLessThan(10 * 1024 * 1024);
}
```

---

## 9. M√©tricas de Neg√≥cio

### üéØ Conceito

Testes devem validar **regras de neg√≥cio** explicitamente. M√©tricas de cobertura de dom√≠nio.

### üìä Business Rule Coverage

```
Business Rule Coverage = (Regras Testadas / Regras Documentadas) √ó 100
```

**Exemplo:**

```java
// Regra: Desconto progressivo
// - 10 a 49 itens: 5%
// - 50 a 99 itens: 10%
// - 100+: 15%

@ParameterizedTest
@CsvSource({
    "9, 0.0",    // abaixo do limite
    "10, 0.05",  // primeira faixa
    "49, 0.05",  // boundary superior primeira faixa
    "50, 0.10",  // segunda faixa
    "99, 0.10",  // boundary superior segunda faixa
    "100, 0.15", // terceira faixa
    "1000, 0.15" // acima
})
void deveAplicarDescontoProgressivo(int quantity, double expectedDiscount) {
    assertEquals(expectedDiscount, calculator.getDiscount(quantity));
}
// Business Rule Coverage: 100% (todas as faixas testadas)
```

### üìà Rastreabilidade

```java
// Linking testes a requisitos
@Test
@Tag("REQ-123") // requirement ID
@DisplayName("REQ-123: Cliente VIP tem frete gr√°tis acima de R$ 100")
void clienteVipDeveTerFreteGratisAcimaDeR100() {
    // ...
}
```

**Relat√≥rio de rastreabilidade:**

```bash
# Gerar matriz de cobertura de requisitos
grep -r "@Tag(\"REQ-" src/test/ | awk -F'"' '{print $2}' | sort | uniq > /tmp/tested-reqs.txt

# Comparar com requisitos documentados
comm -23 docs/requirements.txt /tmp/tested-reqs.txt > /tmp/untested-reqs.txt

echo "üìä Requisitos sem testes:"
cat /tmp/untested-reqs.txt
```

---

## 10. Dashboard e Visualiza√ß√£o

### üéØ Objetivo

Consolidar m√©tricas em dashboard √∫nico para visibilidade de time.

### üìä Exemplo: Grafana + Prometheus

**Prometheus metrics export:**

```java
// Spring Boot Actuator + Micrometer
@Component
public class TestMetricsExporter {

    private final MeterRegistry registry;

    public TestMetricsExporter(MeterRegistry registry) {
        this.registry = registry;

        // Mutation Score
        Gauge.builder("test.mutation.score", this, TestMetricsExporter::getMutationScore)
             .description("Mutation score percentage")
             .register(registry);

        // Flaky Rate
        Gauge.builder("test.flaky.rate", this, TestMetricsExporter::getFlakyRate)
             .description("Flaky test rate percentage")
             .register(registry);

        // Lead Time
        Gauge.builder("test.lead.time.seconds", this, TestMetricsExporter::getLeadTimeSeconds)
             .description("Test lead time in seconds")
             .register(registry);
    }

    private double getMutationScore() {
        // Ler de PITest XML report
        return parsePitestReport();
    }

    private double getFlakyRate() {
        // Calcular baseado em hist√≥rico
        return calculateFlakyRate();
    }

    private double getLeadTimeSeconds() {
        // M√©dia das √∫ltimas 10 execu√ß√µes
        return averageLeadTime();
    }
}
```

**Grafana Dashboard JSON:**

```json
{
  "dashboard": {
    "title": "Test Quality Metrics",
    "panels": [
      {
        "title": "Mutation Score",
        "type": "gauge",
        "targets": [
          {
            "expr": "test_mutation_score",
            "legendFormat": "Mutation %"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "thresholds": {
              "mode": "absolute",
              "steps": [
                { "value": 0, "color": "red" },
                { "value": 60, "color": "yellow" },
                { "value": 80, "color": "green" }
              ]
            }
          }
        }
      },
      {
        "title": "Flaky Rate (7 days)",
        "type": "stat",
        "targets": [
          {
            "expr": "test_flaky_rate",
            "legendFormat": "Flaky %"
          }
        ]
      },
      {
        "title": "Lead Time Trend",
        "type": "graph",
        "targets": [
          {
            "expr": "test_lead_time_seconds",
            "legendFormat": "Lead Time (s)"
          }
        ]
      }
    ]
  }
}
```

### üìà Template de README Metrics Badge

```markdown
# Project Name

![Mutation Score](https://img.shields.io/badge/mutation-85%25-green)
![Diff Coverage](https://img.shields.io/badge/diff%20coverage-92%25-brightgreen)
![Flaky Rate](https://img.shields.io/badge/flaky%20rate-0.2%25-green)
![Lead Time](https://img.shields.io/badge/lead%20time-3.5min-yellow)

## Quality Metrics

| Metric          | Current | Target  | Status |
| --------------- | ------- | ------- | ------ |
| Mutation Score  | 85%     | 80%     | ‚úÖ     |
| Diff Coverage   | 92%     | 85%     | ‚úÖ     |
| Flaky Rate      | 0.2%    | < 1%    | ‚úÖ     |
| Lead Time (CI)  | 3.5 min | < 5 min | ‚úÖ     |
| Branch Coverage | 88%     | 85%     | ‚úÖ     |
```

---

## üìö Checklist de Implementa√ß√£o

### Fase 1: Coleta B√°sica

- [ ] Configurar JaCoCo ou equivalente
- [ ] Configurar PITest para mutation testing
- [ ] Configurar Codecov ou SonarQube
- [ ] Estabelecer baselines

### Fase 2: Quality Gates

- [ ] Definir thresholds para cada m√©trica
- [ ] Implementar checks no CI/CD
- [ ] Configurar alertas para regress√µes
- [ ] Documentar exce√ß√µes

### Fase 3: Automa√ß√£o

- [ ] Scripts de coleta automatizada
- [ ] Dashboard centralizado
- [ ] Relat√≥rios peri√≥dicos (semanal)
- [ ] Integra√ß√£o com ferramentas de issue tracking

### Fase 4: Cultura

- [ ] Treinar time nas m√©tricas
- [ ] Incorporar em code reviews
- [ ] Retrospectivas baseadas em dados
- [ ] Celebrar melhorias

---

## üéØ Pr√≥ximos Passos

1. **Implementar coleta b√°sica** (Fase 1)
2. **Estabelecer thresholds iniciais** (conservadores)
3. **Rodar por 2 semanas** para calibrar
4. **Ajustar metas** baseado em dados reais
5. **Automatizar enforcement** com quality gates

---

## üìñ Refer√™ncias

- [PITest Documentation](https://pitest.org/)
- [JaCoCo Documentation](https://www.jacoco.org/jacoco/)
- [Codecov Best Practices](https://docs.codecov.com/docs)
- [Google Testing Blog - Flaky Tests](https://testing.googleblog.com/)
- [Martin Fowler - Test Coverage](https://martinfowler.com/bliki/TestCoverage.html)

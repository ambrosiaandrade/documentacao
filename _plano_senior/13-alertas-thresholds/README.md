# üö® Fase 13: Alertas e Thresholds - Guia Completo

> **Objetivo:** Dominar alertas eficazes, thresholds din√¢micos e observabilidade operacional.

---

## üìö Vis√£o Geral

Esta fase cobre a **ci√™ncia de alertas**: desde fundamentos (SLI/SLO/SLA) at√© implementa√ß√£o avan√ßada (anomaly detection, chaos testing). O objetivo √© criar alertas **acion√°veis, precisos e n√£o fatigantes**.

---

## üìë M√≥dulos

### [13.1 - Fundamentos de Alertas](13.1-fundamentos-alertas.md)

**Conceitos:** SLI/SLO/SLA, Error Budget, Golden Signals  
**Ferramentas:** Prometheus, Micrometer  
**Dura√ß√£o:** 3-4 horas

**Aprenda:**

- Diferen√ßa entre SLI (medi√ß√£o), SLO (meta), SLA (contrato)
- Calcular Error Budget e Burn Rate
- Golden Signals (Latency, Traffic, Errors, Saturation)
- Alert design principles (actionable, symptomatic, timely)
- Alert taxonomy (critical/warning/info)

**Hands-on:**

```java
// Calcular Error Budget
var errorBudget = errorBudgetService.calculateErrorBudget(99.9, 30);
System.out.println("Budget consumed: " + errorBudget.budgetConsumed() + "%");
System.out.println("Policy: " + errorBudget.policy());
```

---

### [13.2 - Prometheus Alerting](13.2-prometheus-alerting.md)

**Conceitos:** AlertManager, PromQL, Routing, Inhibition  
**Ferramentas:** Prometheus, AlertManager, PagerDuty, Slack  
**Dura√ß√£o:** 4-5 horas

**Aprenda:**

- Configurar AlertManager (routing, grouping, silencing)
- Escrever alert rules com PromQL
- Multi-window alerts (burn rate)
- Inhibition rules (evitar ru√≠do)
- Integrations (PagerDuty, Slack, Email)

**Hands-on:**

```yaml
# Burn rate alert (multi-window)
- alert: FastBurnRate
  expr: |
    sli:error_rate:5m > (10 * slo:error_budget)
    and
    sli:error_rate:1h > (10 * slo:error_budget)
  for: 2m
  labels:
    severity: critical
```

---

### [13.3 - Thresholds Din√¢micos](13.3-thresholds-dinamicos.md)

**Conceitos:** Baselines adaptativos, Anomaly detection, Seasonality  
**Ferramentas:** Prometheus, Prophet, ARIMA, Isolation Forest  
**Dura√ß√£o:** 5-6 horas

**Aprenda:**

- Calcular baseline adaptativo (m√©dia + N \* stddev)
- Z-Score para anomaly detection
- Rate of Change (ROC) para detectar mudan√ßas s√∫bitas
- Percentiles e outliers (IQR method)
- Sazonalidade (dia da semana, hora do dia)
- Machine Learning (Prophet, ARIMA, Isolation Forest)

**Hands-on:**

```yaml
# Threshold din√¢mico: baseline + 3œÉ
- record: threshold:latency_p99:dynamic
  expr: |
    baseline:latency_p99:7d + (3 * baseline:latency_p99:stddev)

- alert: HighLatencyDynamic
  expr: |
    histogram_quantile(0.99, rate(http_requests_seconds_bucket[5m])) 
    > threshold:latency_p99:dynamic
```

---

### [13.4 - Alert Fatigue](13.4-alert-fatigue.md)

**Conceitos:** Alert hygiene, Runbooks, On-call, Post-mortem  
**Ferramentas:** PagerDuty, Opsgenie, Kubernetes  
**Dura√ß√£o:** 4-5 horas

**Aprenda:**

- Identificar e reduzir alert fatigue
- M√©tricas: False positive rate, MTTA, MTTR
- Alert tuning (calibra√ß√£o de thresholds)
- Runbook automation
- Auto-remediation (rollback, scaling, circuit breaker)
- On-call rotation e escalation
- Post-mortem process (5 Whys, action items)

**Hands-on:**

```java
// Auto-remediation: Rollback em error rate alto
if (alert.getName().equals("HighErrorRate")) {
    var deployment = alert.getLabels().get("deployment");
    var lastDeployTime = k8s.getLastDeployTime(deployment);

    if (Duration.between(lastDeployTime, Instant.now()).toMinutes() < 120) {
        k8s.rollback(deployment);
    }
}
```

---

### [13.5 - Testing Alerts](13.5-testing-alerts.md)

**Conceitos:** Alert testing, Chaos engineering, Observability tests  
**Ferramentas:** Testcontainers, Chaos Toolkit, Chaos Mesh  
**Dura√ß√£o:** 5-6 horas

**Aprenda:**

- Pir√¢mide de testes de alertas (Unit/Integration/E2E)
- Testcontainers com Prometheus + AlertManager
- Alert simulation (mock metrics)
- Chaos engineering (kill pods, saturar CPU)
- Contract testing (validar m√©tricas existem)
- SLO testing (validar compliance)

**Hands-on:**

```java
@Test
void testHighLatencyAlertFires() {
    metricsExporter.simulateHighLatency(Duration.ofMillis(600));

    await().atMost(Duration.ofMinutes(6))
           .until(() -> alertManager.hasAlert("HighLatency", Severity.WARNING));
}
```

---

## üéØ Objetivos de Aprendizado

Ao completar esta fase, voc√™ ser√° capaz de:

- ‚úÖ Definir SLI/SLO/SLA para servi√ßos cr√≠ticos
- ‚úÖ Calcular Error Budget e tomar decis√µes baseadas nele
- ‚úÖ Implementar Golden Signals (latency, traffic, errors, saturation)
- ‚úÖ Escrever alert rules eficazes com PromQL
- ‚úÖ Configurar routing, grouping e inhibition no AlertManager
- ‚úÖ Criar thresholds din√¢micos (baseline + N \* stddev)
- ‚úÖ Implementar anomaly detection (Z-Score, ROC, IQR)
- ‚úÖ Integrar ML (Prophet, ARIMA) para forecasting
- ‚úÖ Reduzir alert fatigue (false positive rate < 5%)
- ‚úÖ Automatizar runbooks e remediation
- ‚úÖ Configurar on-call rotation com escalation
- ‚úÖ Escrever post-mortems eficazes (5 Whys)
- ‚úÖ Testar alertas com Testcontainers e Chaos Engineering

---

## üìä M√©tricas de Sucesso

### Indicadores de Qualidade

| M√©trica                             | Target   | Como Medir                                           |
| ----------------------------------- | -------- | ---------------------------------------------------- |
| **False Positive Rate**             | < 5%     | (Alertas resolvidos sem a√ß√£o / Total alertas) \* 100 |
| **Alert Noise Ratio**               | < 200%   | (Alertas warning+info / Alertas critical) \* 100     |
| **MTTA (Mean Time to Acknowledge)** | < 5 min  | Tempo m√©dio entre alert fire e ACK                   |
| **MTTR (Mean Time to Resolve)**     | < 30 min | Tempo m√©dio entre alert fire e resolve               |
| **SLO Compliance**                  | > 99%    | % de tempo dentro do SLO (√∫ltimos 30 dias)           |
| **Error Budget Remaining**          | > 20%    | Budget n√£o consumido (evitar freeze)                 |
| **Runbook Coverage**                | 100%     | % de alertas critical com runbook                    |
| **Auto-Remediation Rate**           | > 50%    | % de alertas resolvidos automaticamente              |

### Checklist de Pronto

- [ ] Todos servi√ßos cr√≠ticos t√™m SLI/SLO definidos
- [ ] Error Budget calculado e dashboard vis√≠vel
- [ ] Golden Signals monitorados (latency, traffic, errors, saturation)
- [ ] Alertas classificados (critical/warning/info)
- [ ] Thresholds calibrados (false positive rate < 5%)
- [ ] AlertManager com routing por severidade
- [ ] Inhibition rules para evitar ru√≠do
- [ ] Burn rate alerts (multi-window)
- [ ] Thresholds din√¢micos (baseline + N \* stddev)
- [ ] Anomaly detection implementada (Z-Score ou ML)
- [ ] Runbooks documentados para alertas critical
- [ ] Auto-remediation para alertas comuns
- [ ] On-call rotation configurada (PagerDuty/Opsgenie)
- [ ] Post-mortem process definido
- [ ] Alertas testados (Testcontainers + Chaos)

---

## üõ†Ô∏è Ferramentas e Depend√™ncias

### Essenciais

```xml
<!-- Micrometer (m√©tricas) -->
<dependency>
    <groupId>io.micrometer</groupId>
    <artifactId>micrometer-registry-prometheus</artifactId>
</dependency>

<!-- Spring Boot Actuator -->
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-actuator</artifactId>
</dependency>

<!-- Testcontainers -->
<dependency>
    <groupId>org.testcontainers</groupId>
    <artifactId>testcontainers</artifactId>
    <version>1.19.3</version>
    <scope>test</scope>
</dependency>
```

### Infraestrutura

```yaml
# docker-compose.yml
version: "3.8"
services:
  prometheus:
    image: prom/prometheus:v2.48.0
    ports:
      - "9090:9090"

  alertmanager:
    image: prom/alertmanager:v0.26.0
    ports:
      - "9093:9093"

  grafana:
    image: grafana/grafana:10.2.0
    ports:
      - "3000:3000"
```

### Machine Learning (Opcional)

```bash
pip install fbprophet statsmodels scikit-learn pandas
```

---

## üìö Refer√™ncias

### Livros

- **Site Reliability Engineering** (Google) - Cap√≠tulos sobre monitoring e alerting
- **The Site Reliability Workbook** (Google) - Alerting on SLOs
- **Observability Engineering** (Charity Majors) - Modern observability practices

### Documenta√ß√£o

- [Prometheus Alerting](https://prometheus.io/docs/alerting/latest/overview/)
- [Google SRE Book - Monitoring](https://sre.google/sre-book/monitoring-distributed-systems/)
- [AlertManager Configuration](https://prometheus.io/docs/alerting/latest/configuration/)
- [PromQL Cheat Sheet](https://promlabs.com/promql-cheat-sheet/)

### Ferramentas

- [Prometheus](https://prometheus.io/)
- [Grafana](https://grafana.com/)
- [PagerDuty](https://www.pagerduty.com/)
- [Chaos Toolkit](https://chaostoolkit.org/)
- [Chaos Mesh](https://chaos-mesh.org/)

---

## üéì Exerc√≠cios Pr√°ticos

### B√°sico (2-3 horas)

1. Configurar Prometheus + AlertManager localmente
2. Criar alert rule para lat√™ncia p99 > 500ms
3. Integrar com Slack para notifica√ß√µes

### Intermedi√°rio (4-5 horas)

4. Calcular Error Budget e Burn Rate
5. Implementar threshold din√¢mico (baseline + 3œÉ)
6. Configurar inhibition rules (InstanceDown silencia outros)

### Avan√ßado (6-8 horas)

7. Setup Testcontainers com Prometheus + AlertManager
8. Criar chaos experiment (kill pod + validar alertas)
9. Implementar auto-remediation (rollback em error rate alto)
10. Integrar Prophet para anomaly detection

---

## üöÄ Pr√≥ximos Passos

Ap√≥s completar esta fase:

- **Fase 14:** Big O Notation (An√°lise de Complexidade)
- **Fase 15:** Code Review (Boas Pr√°ticas)
- **Revis√£o:** Integra√ß√£o de todas as fases

---

## üìù Notas Importantes

### Trade-offs

**Alertas demais vs poucos:**

- ‚ùå Muitos alertas ‚Üí Alert fatigue, ignorar cr√≠ticos
- ‚ùå Poucos alertas ‚Üí Problemas n√£o detectados
- ‚úÖ Balanceado: Critical < 10 alertas/dia, Warning < 50 alertas/dia

**Thresholds fixos vs din√¢micos:**

- ‚úÖ Fixos: Simples, f√°cil debug, bom para m√©tricas est√°veis
- ‚úÖ Din√¢micos: Menos falsos positivos, adapta a sazonalidade
- ‚ö†Ô∏è Din√¢micos: Complexidade maior, pode mascarar problemas reais

**Auto-remediation vs manual:**

- ‚úÖ Auto: Resolve r√°pido, reduz MTTR, escala melhor
- ‚ö†Ô∏è Auto: Risco de mascarar root cause, pode piorar situa√ß√£o
- üí° Recomenda√ß√£o: Auto para a√ß√µes seguras (scaling), manual para a√ß√µes destrutivas (rollback)

---

**Dura√ß√£o Total:** 20-25 horas  
**Dificuldade:** üî•üî•üî•üî• (Avan√ßado)  
**Pr√©-requisitos:** Fase 3 (Avan√ßado), Fase 8 (M√©tricas), conhecimento de Prometheus

---

**Anterior:** Fase 12 - Banco de Dados  
**Pr√≥ximo:** Fase 14 - Big O Notation
